/Users/simon/miniconda3/envs/algo_trading/bin/python /Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/test_run_models.py
['BTCUSD_vwap', 'ETHUSD_vwap', 'USDTUSD_vwap', 'XRPUSD_vwap', 'ADAUSD_vwap', 'DOGEUSD_vwap', 'LTCUSD_vwap', '5_YR', '7_YR', '10_YR', '20_YR', '4_Wk_Bank_Discount_Rate', '13_Wk_Bank_Discount_Rate', '52_Wk_Bank_Discount_Rate', 'tips', 'uk_20y_nif', 'uk_10y_nif', 'uk_5y_nif', 'uk_bank_rate', 'EM_HY', 'US_Corp', 'vix', 'usd_nominal', 'usd_real', 'usd_euro', 'gold_london', 'silver_london', 'ma7', 'ma21', '26ema', '12ema', 'MACD', '20sd', 'upper_band', 'lower_band', 'ema', 'RSI', 'absolute_3_comp', 'angle_3_comp', 'absolute_6_comp', 'angle_6_comp', 'absolute_9_comp', 'angle_9_comp']
number of features: 43
X_Train_val (1288, 43), y_train_val (1258, 1)
X_test(522, 30, 43), y_test (522, 1)
/Users/simon/.local/lib/python3.10/site-packages/numpy/lib/format.py:366: UserWarning: metadata on a dtype may be saved or ignored, but will raise if saved when read. Use another form of storage.
  d['descr'] = dtype_to_descr(array.dtype)
['BTCUSD_vwap', 'ETHUSD_vwap', 'USDTUSD_vwap', 'XRPUSD_vwap', 'ADAUSD_vwap', 'DOGEUSD_vwap', 'LTCUSD_vwap', '5_YR', '7_YR', '10_YR', '20_YR', '4_Wk_Bank_Discount_Rate', '13_Wk_Bank_Discount_Rate', '52_Wk_Bank_Discount_Rate', 'tips', 'uk_20y_nif', 'uk_10y_nif', 'uk_5y_nif', 'uk_bank_rate', 'EM_HY', 'US_Corp', 'vix', 'usd_nominal', 'usd_real', 'usd_euro', 'gold_london', 'silver_london', 'ma7', 'ma21', '26ema', '12ema', 'MACD', '20sd', 'upper_band', 'lower_band', 'ema', 'RSI', 'absolute_3_comp', 'angle_3_comp', 'absolute_6_comp', 'angle_6_comp', 'absolute_9_comp', 'angle_9_comp']
number of features: 43
X_Train(1193, 30, 43), y_train (1193, 1)
X_val(495, 30, 43), y_val (495, 1)
X_test(62, 30, 43), y_test (62, 1)
input_dim: 30, feature_size: 43, output_dim: 1
Metal device set to: Apple M2 Max

systemMemory: 32.00 GB
maxCacheSize: 10.67 GB

/Users/simon/.local/lib/python3.10/site-packages/numpy/lib/format.py:366: UserWarning: metadata on a dtype may be saved or ignored, but will raise if saved when read. Use another form of storage.
  d['descr'] = dtype_to_descr(array.dtype)
2023-05-01 16:00:03.924170: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
Epoch 1/50
10/10 - 2s - loss: 1.1497 - val_loss: 0.1375 - 2s/epoch - 189ms/step
Epoch 2/50
10/10 - 0s - loss: 0.1869 - val_loss: 0.0731 - 428ms/epoch - 43ms/step
Epoch 3/50
10/10 - 0s - loss: 0.0575 - val_loss: 0.0886 - 435ms/epoch - 44ms/step
Epoch 4/50
10/10 - 0s - loss: 0.0539 - val_loss: 0.1015 - 428ms/epoch - 43ms/step
Epoch 5/50
10/10 - 0s - loss: 0.0239 - val_loss: 0.1185 - 429ms/epoch - 43ms/step
Epoch 6/50
10/10 - 0s - loss: 0.0191 - val_loss: 0.1308 - 440ms/epoch - 44ms/step
Epoch 7/50
10/10 - 0s - loss: 0.0181 - val_loss: 0.1334 - 442ms/epoch - 44ms/step
Epoch 8/50
10/10 - 0s - loss: 0.0150 - val_loss: 0.1322 - 446ms/epoch - 45ms/step
Epoch 9/50
10/10 - 0s - loss: 0.0134 - val_loss: 0.1304 - 452ms/epoch - 45ms/step
Epoch 10/50
10/10 - 0s - loss: 0.0120 - val_loss: 0.1277 - 459ms/epoch - 46ms/step
Epoch 11/50
10/10 - 0s - loss: 0.0109 - val_loss: 0.1236 - 458ms/epoch - 46ms/step
Epoch 12/50
10/10 - 0s - loss: 0.0100 - val_loss: 0.1189 - 468ms/epoch - 47ms/step
Epoch 13/50
10/10 - 0s - loss: 0.0092 - val_loss: 0.1145 - 462ms/epoch - 46ms/step
Epoch 14/50
10/10 - 0s - loss: 0.0085 - val_loss: 0.1106 - 465ms/epoch - 47ms/step
Epoch 15/50
10/10 - 0s - loss: 0.0079 - val_loss: 0.1071 - 466ms/epoch - 47ms/step
Epoch 16/50
10/10 - 0s - loss: 0.0074 - val_loss: 0.1040 - 446ms/epoch - 45ms/step
Epoch 17/50
10/10 - 0s - loss: 0.0069 - val_loss: 0.1012 - 456ms/epoch - 46ms/step
Epoch 18/50
10/10 - 0s - loss: 0.0065 - val_loss: 0.0988 - 458ms/epoch - 46ms/step
Epoch 19/50
10/10 - 0s - loss: 0.0062 - val_loss: 0.0966 - 450ms/epoch - 45ms/step
Epoch 20/50
10/10 - 0s - loss: 0.0059 - val_loss: 0.0947 - 454ms/epoch - 45ms/step
Epoch 21/50
10/10 - 0s - loss: 0.0056 - val_loss: 0.0931 - 446ms/epoch - 45ms/step
Epoch 22/50
10/10 - 0s - loss: 0.0054 - val_loss: 0.0916 - 446ms/epoch - 45ms/step
Epoch 23/50
10/10 - 0s - loss: 0.0052 - val_loss: 0.0903 - 461ms/epoch - 46ms/step
Epoch 24/50
10/10 - 0s - loss: 0.0050 - val_loss: 0.0893 - 476ms/epoch - 48ms/step
Epoch 25/50
10/10 - 0s - loss: 0.0048 - val_loss: 0.0883 - 467ms/epoch - 47ms/step
Epoch 26/50
10/10 - 0s - loss: 0.0046 - val_loss: 0.0876 - 467ms/epoch - 47ms/step
Epoch 27/50
10/10 - 0s - loss: 0.0044 - val_loss: 0.0870 - 470ms/epoch - 47ms/step
Epoch 28/50
10/10 - 0s - loss: 0.0043 - val_loss: 0.0865 - 470ms/epoch - 47ms/step
Epoch 29/50
10/10 - 0s - loss: 0.0042 - val_loss: 0.0861 - 477ms/epoch - 48ms/step
Epoch 30/50
10/10 - 0s - loss: 0.0040 - val_loss: 0.0858 - 472ms/epoch - 47ms/step
Epoch 31/50
10/10 - 0s - loss: 0.0039 - val_loss: 0.0856 - 485ms/epoch - 48ms/step
Epoch 32/50
10/10 - 0s - loss: 0.0038 - val_loss: 0.0855 - 485ms/epoch - 49ms/step
Epoch 33/50
10/10 - 0s - loss: 0.0037 - val_loss: 0.0854 - 479ms/epoch - 48ms/step
Epoch 34/50
10/10 - 0s - loss: 0.0036 - val_loss: 0.0854 - 473ms/epoch - 47ms/step
Epoch 35/50
10/10 - 0s - loss: 0.0035 - val_loss: 0.0855 - 472ms/epoch - 47ms/step
Epoch 36/50
10/10 - 0s - loss: 0.0034 - val_loss: 0.0857 - 483ms/epoch - 48ms/step
Epoch 37/50
10/10 - 0s - loss: 0.0033 - val_loss: 0.0858 - 489ms/epoch - 49ms/step
Epoch 38/50
10/10 - 0s - loss: 0.0032 - val_loss: 0.0861 - 476ms/epoch - 48ms/step
Epoch 39/50
10/10 - 0s - loss: 0.0031 - val_loss: 0.0863 - 467ms/epoch - 47ms/step
Epoch 40/50
10/10 - 0s - loss: 0.0030 - val_loss: 0.0866 - 481ms/epoch - 48ms/step
Epoch 41/50
10/10 - 0s - loss: 0.0029 - val_loss: 0.0869 - 475ms/epoch - 48ms/step
Epoch 42/50
10/10 - 0s - loss: 0.0029 - val_loss: 0.0872 - 479ms/epoch - 48ms/step
Epoch 43/50
10/10 - 0s - loss: 0.0028 - val_loss: 0.0876 - 470ms/epoch - 47ms/step
Epoch 44/50
10/10 - 0s - loss: 0.0027 - val_loss: 0.0880 - 471ms/epoch - 47ms/step
Epoch 45/50
10/10 - 0s - loss: 0.0027 - val_loss: 0.0883 - 487ms/epoch - 49ms/step
Epoch 46/50
10/10 - 0s - loss: 0.0026 - val_loss: 0.0887 - 480ms/epoch - 48ms/step
Epoch 47/50
10/10 - 0s - loss: 0.0025 - val_loss: 0.0891 - 474ms/epoch - 47ms/step
Epoch 48/50
10/10 - 0s - loss: 0.0025 - val_loss: 0.0896 - 465ms/epoch - 46ms/step
Epoch 49/50
10/10 - 0s - loss: 0.0024 - val_loss: 0.0900 - 479ms/epoch - 48ms/step
Epoch 50/50
10/10 - 0s - loss: 0.0024 - val_loss: 0.0904 - 490ms/epoch - 49ms/step
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 gru (GRU)                   (None, 30, 128)           66432

 gru_1 (GRU)                 (None, 64)                37248

 dense (Dense)               (None, 32)                2080

 dense_1 (Dense)             (None, 1)                 33

=================================================================
Total params: 105,793
Trainable params: 105,793
Non-trainable params: 0
_________________________________________________________________
None
Price Prediction Accuracy is 0.5104777870913663
----- Train_RMSE_GRU ----- 936.3497374220523
Price Prediction Accuracy is 0.5131313131313131
----- Val_RMSE_GRU ----- 2714.9691647911295
Price Prediction Accuracy is 0.5161290322580645
----- Test_RMSE_GRU ----- 1651.6318534577986
input_dim: 30, feature_size: 43, output_dim: 1
/Users/simon/miniconda3/envs/algo_trading/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Epoch 1/50
19/19 - 3s - loss: 0.2739 - val_loss: 0.3689 - 3s/epoch - 136ms/step
Epoch 2/50
19/19 - 0s - loss: 0.7700 - val_loss: 0.8854 - 424ms/epoch - 22ms/step
Epoch 3/50
19/19 - 0s - loss: 1.2684 - val_loss: 0.6021 - 427ms/epoch - 22ms/step
Epoch 4/50
19/19 - 0s - loss: 0.9162 - val_loss: 3.3331 - 423ms/epoch - 22ms/step
Epoch 5/50
19/19 - 0s - loss: 1.2132 - val_loss: 2.1765 - 422ms/epoch - 22ms/step
Epoch 6/50
19/19 - 0s - loss: 1.1359 - val_loss: 2.4107 - 424ms/epoch - 22ms/step
Epoch 7/50
19/19 - 0s - loss: 0.9727 - val_loss: 0.3077 - 421ms/epoch - 22ms/step
Epoch 8/50
19/19 - 0s - loss: 0.0895 - val_loss: 0.1497 - 427ms/epoch - 22ms/step
Epoch 9/50
19/19 - 0s - loss: 0.0125 - val_loss: 0.1100 - 424ms/epoch - 22ms/step
Epoch 10/50
19/19 - 0s - loss: 0.0068 - val_loss: 0.1179 - 425ms/epoch - 22ms/step
Epoch 11/50
19/19 - 0s - loss: 0.0053 - val_loss: 0.1185 - 424ms/epoch - 22ms/step
Epoch 12/50
19/19 - 0s - loss: 0.0044 - val_loss: 0.1226 - 424ms/epoch - 22ms/step
Epoch 13/50
19/19 - 0s - loss: 0.0039 - val_loss: 0.1281 - 419ms/epoch - 22ms/step
Epoch 14/50
19/19 - 0s - loss: 0.0035 - val_loss: 0.1323 - 424ms/epoch - 22ms/step
Epoch 15/50
19/19 - 0s - loss: 0.0032 - val_loss: 0.1364 - 423ms/epoch - 22ms/step
Epoch 16/50
19/19 - 0s - loss: 0.0030 - val_loss: 0.1402 - 422ms/epoch - 22ms/step
Epoch 17/50
19/19 - 0s - loss: 0.0028 - val_loss: 0.1432 - 426ms/epoch - 22ms/step
Epoch 18/50
19/19 - 0s - loss: 0.0026 - val_loss: 0.1458 - 423ms/epoch - 22ms/step
Epoch 19/50
19/19 - 0s - loss: 0.0025 - val_loss: 0.1479 - 421ms/epoch - 22ms/step
Epoch 20/50
19/19 - 0s - loss: 0.0024 - val_loss: 0.1494 - 422ms/epoch - 22ms/step
Epoch 21/50
19/19 - 0s - loss: 0.0024 - val_loss: 0.1506 - 422ms/epoch - 22ms/step
Epoch 22/50
19/19 - 0s - loss: 0.0023 - val_loss: 0.1515 - 423ms/epoch - 22ms/step
Epoch 23/50
19/19 - 0s - loss: 0.0022 - val_loss: 0.1522 - 425ms/epoch - 22ms/step
Epoch 24/50
19/19 - 0s - loss: 0.0022 - val_loss: 0.1527 - 423ms/epoch - 22ms/step
Epoch 25/50
19/19 - 0s - loss: 0.0021 - val_loss: 0.1531 - 422ms/epoch - 22ms/step
Epoch 26/50
19/19 - 0s - loss: 0.0021 - val_loss: 0.1534 - 423ms/epoch - 22ms/step
Epoch 27/50
19/19 - 0s - loss: 0.0020 - val_loss: 0.1537 - 417ms/epoch - 22ms/step
Epoch 28/50
19/19 - 0s - loss: 0.0020 - val_loss: 0.1541 - 421ms/epoch - 22ms/step
Epoch 29/50
19/19 - 0s - loss: 0.0019 - val_loss: 0.1545 - 424ms/epoch - 22ms/step
Epoch 30/50
19/19 - 0s - loss: 0.0019 - val_loss: 0.1549 - 425ms/epoch - 22ms/step
Epoch 31/50
19/19 - 0s - loss: 0.0018 - val_loss: 0.1554 - 423ms/epoch - 22ms/step
Epoch 32/50
19/19 - 0s - loss: 0.0018 - val_loss: 0.1559 - 424ms/epoch - 22ms/step
Epoch 33/50
19/19 - 0s - loss: 0.0018 - val_loss: 0.1565 - 424ms/epoch - 22ms/step
Epoch 34/50
19/19 - 0s - loss: 0.0017 - val_loss: 0.1571 - 424ms/epoch - 22ms/step
Epoch 35/50
19/19 - 0s - loss: 0.0017 - val_loss: 0.1578 - 424ms/epoch - 22ms/step
Epoch 36/50
19/19 - 0s - loss: 0.0017 - val_loss: 0.1585 - 426ms/epoch - 22ms/step
Epoch 37/50
19/19 - 0s - loss: 0.0016 - val_loss: 0.1593 - 429ms/epoch - 23ms/step
Epoch 38/50
19/19 - 0s - loss: 0.0016 - val_loss: 0.1601 - 425ms/epoch - 22ms/step
Epoch 39/50
19/19 - 0s - loss: 0.0016 - val_loss: 0.1609 - 424ms/epoch - 22ms/step
Epoch 40/50
19/19 - 0s - loss: 0.0015 - val_loss: 0.1618 - 423ms/epoch - 22ms/step
Epoch 41/50
19/19 - 0s - loss: 0.0015 - val_loss: 0.1627 - 420ms/epoch - 22ms/step
Epoch 42/50
19/19 - 0s - loss: 0.0015 - val_loss: 0.1636 - 422ms/epoch - 22ms/step
Epoch 43/50
19/19 - 0s - loss: 0.0014 - val_loss: 0.1645 - 422ms/epoch - 22ms/step
Epoch 44/50
19/19 - 0s - loss: 0.0014 - val_loss: 0.1654 - 423ms/epoch - 22ms/step
Epoch 45/50
19/19 - 0s - loss: 0.0014 - val_loss: 0.1664 - 416ms/epoch - 22ms/step
Epoch 46/50
19/19 - 0s - loss: 0.0014 - val_loss: 0.1674 - 420ms/epoch - 22ms/step
Epoch 47/50
19/19 - 0s - loss: 0.0013 - val_loss: 0.1684 - 423ms/epoch - 22ms/step
Epoch 48/50
19/19 - 0s - loss: 0.0013 - val_loss: 0.1692 - 412ms/epoch - 22ms/step
Epoch 49/50
19/19 - 0s - loss: 0.0013 - val_loss: 0.1704 - 421ms/epoch - 22ms/step
Epoch 50/50
19/19 - 0s - loss: 0.0013 - val_loss: 0.1710 - 425ms/epoch - 22ms/step
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 bidirectional (Bidirectiona  (None, 256)              176128
 l)

 dense_2 (Dense)             (None, 64)                16448

 dense_3 (Dense)             (None, 1)                 65

=================================================================
Total params: 192,641
Trainable params: 192,641
Non-trainable params: 0
_________________________________________________________________
None
Price Prediction Accuracy is 0.5280804694048616
----- Train_RMSE_LSTM ----- 936.3472668881317
Price Prediction Accuracy is 0.5252525252525253
----- Val_RMSE_LSTM ----- 2715.0380487892025
Price Prediction Accuracy is 0.5
----- Test_RMSE_LSTM ----- 1651.5350054851565
Running Basic Gan with the following configs: 30_1, 165, 128, 0.00016
output dimension is 1
WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
/Users/simon/miniconda3/envs/algo_trading/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
/Users/simon/miniconda3/envs/algo_trading/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: "`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?"
  return dispatch_target(*args, **kwargs)
epoch 15 d_loss 1.3839921 g_loss 0.6899218
epoch 30 d_loss 1.386053 g_loss 0.6954274
epoch 45 d_loss 1.3864534 g_loss 0.69194347
epoch 60 d_loss 1.3864137 g_loss 0.69344455
epoch 75 d_loss 1.3863394 g_loss 0.69303954
epoch 90 d_loss 1.3862462 g_loss 0.69303614
epoch 105 d_loss 1.3862026 g_loss 0.69334185
 epoch 120 d_loss 1.386251 g_loss 0.693454
epoch 135 d_loss 1.386292 g_loss 0.69279116
epoch 150 d_loss 1.3862674 g_loss 0.69332343
epoch 165 d_loss 1.386301 g_loss 0.69356316
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
pred_price length: 165, real price length: 1258
(1258,)
[ 0.19176182  0.2638321   0.18864442 ...  0.04219506 -0.02406882
 -0.05338869]
price_df shape: (1258, 166)
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df[f'pred_price_{i}'] = y_scaler.inverse_transform(pred_price[i].reshape(-1, 1))
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_Basic_GAN.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  price_df['real_price'] = y_scaler.inverse_transform(real_price.reshape(-1, 1))
WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
Price Prediction Accuracy is 0.5038314176245211
WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
epoch 15 d_loss 7.429715 g_loss -0.03169718
epoch 30 d_loss 4.913662 g_loss -0.055597596
epoch 45 d_loss 2.2964919 g_loss -0.08774668
epoch 60 d_loss 0.3763486 g_loss -0.11728224
epoch 75 d_loss 0.26163948 g_loss -0.13414647
epoch 90 d_loss 0.08016319 g_loss -0.13414872
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
/Users/simon/PycharmProjects/ML-in-Practice-New-Repo-main/model_WGAN_GP.py:33: PerformanceWarning:

DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`

WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
Price Prediction Accuracy is 0.5114942528735632

Process finished with exit code 0
